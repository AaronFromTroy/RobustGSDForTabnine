---
phase: 09-ensure-starting-a-new-project-is-better-worded-even-when-work-withing-an-existing-application-that-is-simply-intializing-gsd-for-the-first
plan: 04
type: execute
wave: 3
depends_on: [09-03]
files_modified:
  - gsd/scripts/codebase-detector.js
  - gsd/scripts/codebase-researcher.js
  - gsd/templates/CODEBASE.md
autonomous: true

must_haves:
  truths:
    - "System can detect if directory contains existing code vs empty/new project"
    - "Detection considers dependency files, source directories, and non-GSD content"
    - "For existing projects, system analyzes tech stack, architecture, conventions"
    - "Research findings saved to .planning/CODEBASE.md for context-aware planning"
  artifacts:
    - path: "gsd/scripts/codebase-detector.js"
      provides: "Existing project detection"
      exports: ["detectExistingCodebase"]
      min_lines: 60
    - path: "gsd/scripts/codebase-researcher.js"
      provides: "Codebase analysis and research"
      exports: ["analyzeCodebase"]
      min_lines: 120
    - path: "gsd/templates/CODEBASE.md"
      provides: "Codebase research template"
      contains: "Tech Stack"
      min_lines: 40
  key_links:
    - from: "new-project.md workflow"
      to: "codebase-detector.js"
      via: "detection step before branching"
      pattern: "node gsd/scripts/codebase-detector.js"
    - from: "codebase-detector.js"
      to: "codebase-researcher.js"
      via: "conditional execution if isExisting: true"
      pattern: "if.*isExisting"
    - from: "codebase-researcher.js"
      to: "CODEBASE.md template"
      via: "template-renderer.js renderTemplate()"
      pattern: "renderTemplate.*CODEBASE"
---

<objective>
Create codebase detection and research scripts to identify existing projects and analyze their tech stack, architecture, and patterns before generating GSD artifacts.

Purpose: The new-project.md workflow (plan 09-03) now references codebase-detector.js and codebase-researcher.js for existing project handling. These scripts must exist and provide the detection + research capabilities that enable context-aware initialization. Without these scripts, the workflow will fail.

Output:
1. codebase-detector.js - detects existing code vs empty directory
2. codebase-researcher.js - analyzes existing projects for tech stack and patterns
3. CODEBASE.md template - structures research findings
</objective>

<execution_context>
@C:\Projects\GSDForTabnine\.planning\phases\09-ensure-starting-a-new-project-is-better-worded-even-when-work-withing-an-existing-application-that-is-simply-intializing-gsd-for-the-first\09-RESEARCH.md
@C:\Projects\GSDForTabnine\.planning\phases\09-ensure-starting-a-new-project-is-better-worded-even-when-work-withing-an-existing-application-that-is-simply-intializing-gsd-for-the-first\09-03-PLAN.md
</execution_context>

<context>
@C:\Projects\GSDForTabnine\.planning\PROJECT.md
@C:\Projects\GSDForTabnine\.planning\ROADMAP.md
@C:\Projects\GSDForTabnine\.planning\STATE.md
@C:\Projects\GSDForTabnine\gsd\scripts\file-ops.js
@C:\Projects\GSDForTabnine\gsd\scripts\template-renderer.js
</context>

<tasks>

<task type="auto">
  <name>Create codebase-detector.js script</name>
  <files>gsd/scripts/codebase-detector.js</files>
  <action>
    Create gsd/scripts/codebase-detector.js as an ESM module that detects existing projects.

    **Structure:**
    ```javascript
    #!/usr/bin/env node
    import fs from 'fs';
    import path from 'path';
    import { fileURLToPath } from 'url';

    const __filename = fileURLToPath(import.meta.url);
    const __dirname = path.dirname(__filename);

    /**
     * Detects if the current directory contains an existing codebase
     * vs being a new/empty project directory.
     *
     * Detection criteria:
     * - Dependency files (package.json, requirements.txt, Cargo.toml, go.mod, etc.)
     * - Common source directories (src/, app/, lib/, components/, etc.)
     * - More than just .git/ and gsd/ in directory
     *
     * @returns {{isExisting: boolean, indicators: string[], confidence: string}}
     */
    export function detectExistingCodebase(targetDir = process.cwd()) {
      const indicators = [];

      // Check for dependency/package manager files
      const depFiles = ['package.json', 'requirements.txt', 'Cargo.toml', 'go.mod', 'composer.json', 'Gemfile', 'pom.xml'];
      const foundDepFiles = depFiles.filter(f => fs.existsSync(path.join(targetDir, f)));
      if (foundDepFiles.length > 0) {
        indicators.push(...foundDepFiles.map(f => `dependency:${f}`));
      }

      // Check for common source directories
      const srcDirs = ['src', 'app', 'lib', 'components', 'pages', 'views', 'controllers', 'models'];
      const foundSrcDirs = srcDirs.filter(d => {
        const dirPath = path.join(targetDir, d);
        return fs.existsSync(dirPath) && fs.statSync(dirPath).isDirectory();
      });
      if (foundSrcDirs.length > 0) {
        indicators.push(...foundSrcDirs.map(d => `directory:${d}`));
      }

      // Check for config files suggesting existing project
      const configFiles = ['.env', '.env.example', 'tsconfig.json', 'jsconfig.json', '.eslintrc.json', 'vite.config.js', 'next.config.js'];
      const foundConfigFiles = configFiles.filter(f => fs.existsSync(path.join(targetDir, f)));
      if (foundConfigFiles.length > 0) {
        indicators.push(...foundConfigFiles.map(f => `config:${f}`));
      }

      // Check for non-GSD, non-git files in root
      const entries = fs.readdirSync(targetDir, { withFileTypes: true });
      const meaningfulEntries = entries.filter(e =>
        !e.name.startsWith('.') &&
        e.name !== 'gsd' &&
        e.name !== 'node_modules' &&
        e.name !== '.planning'
      );
      if (meaningfulEntries.length > 0) {
        indicators.push(...meaningfulEntries.slice(0, 3).map(e => `root:${e.name}`));
      }

      // Determine confidence
      let confidence = 'LOW';
      if (foundDepFiles.length > 0 || foundSrcDirs.length > 0) {
        confidence = 'HIGH';
      } else if (meaningfulEntries.length > 3 || foundConfigFiles.length > 1) {
        confidence = 'MEDIUM';
      }

      const isExisting = indicators.length > 0;

      return { isExisting, indicators, confidence };
    }

    // CLI execution
    if (import.meta.url === `file://${process.argv[1]}`) {
      const result = detectExistingCodebase();
      console.log(JSON.stringify(result, null, 2));
      process.exit(result.isExisting ? 0 : 1);
    }
    ```

    WHY confidence levels: Detection isn't always black/white. A directory with just README.md might be "started" but minimal. Confidence helps workflow decide whether to force research or ask user.

    WHY exclude node_modules and .planning: These are generated by GSD or dependencies. They don't indicate user's code.

    WHY exit code: Exit 0 if existing (isExisting: true), exit 1 if new. Allows shell scripting: `if node codebase-detector.js; then ...`
  </action>
  <verify>
    ```bash
    # Verify script is executable and uses ESM
    head -1 gsd/scripts/codebase-detector.js | grep "#!/usr/bin/env node"
    grep "import.*from" gsd/scripts/codebase-detector.js

    # Test detection (should detect GSD project as existing)
    node gsd/scripts/codebase-detector.js
    ```
    Script should run and output JSON with isExisting, indicators, confidence fields.
  </verify>
  <done>
    codebase-detector.js exists, exports detectExistingCodebase function, runs as CLI, and detects dependency files, source directories, and config files.
  </done>
</task>

<task type="auto">
  <name>Create codebase-researcher.js script</name>
  <files>gsd/scripts/codebase-researcher.js</files>
  <action>
    Create gsd/scripts/codebase-researcher.js as an ESM module that analyzes existing codebases.

    **CRITICAL - template-renderer.js API:** The existing template-renderer.js exports `renderTemplate(templateName, variables, templatesDir)` as a named export. Use this API correctly:
    ```javascript
    import { renderTemplate } from './template-renderer.js';
    // NOT: import templateRenderer from './template-renderer.js'
    // NOT: await templateRenderer.render(...)
    ```

    **Structure:**
    ```javascript
    #!/usr/bin/env node
    import fs from 'fs';
    import path from 'path';
    import { fileURLToPath } from 'url';
    import { renderTemplate } from './template-renderer.js';

    const __filename = fileURLToPath(import.meta.url);
    const __dirname = path.dirname(__filename);

    /**
     * Analyzes an existing codebase for tech stack, architecture, and conventions.
     *
     * Analysis includes:
     * - Tech stack (languages, frameworks, libraries)
     * - Directory structure and architecture patterns
     * - Code conventions (linting, formatting configs)
     * - Testing infrastructure
     * - Build/deployment setup
     *
     * @param {string} targetDir - Directory to analyze
     * @returns {object} Analysis results
     */
    export async function analyzeCodebase(targetDir = process.cwd()) {
      const analysis = {
        techStack: {},
        architecture: {},
        conventions: {},
        testing: {},
        metadata: {
          analyzedAt: new Date().toISOString(),
          targetDir: targetDir
        }
      };

      // Detect languages and frameworks
      analysis.techStack = detectTechStack(targetDir);

      // Analyze directory structure
      analysis.architecture = analyzeArchitecture(targetDir);

      // Detect code conventions
      analysis.conventions = detectConventions(targetDir);

      // Check testing setup
      analysis.testing = detectTesting(targetDir);

      return analysis;
    }

    function detectTechStack(dir) {
      const stack = {
        languages: [],
        frameworks: [],
        libraries: [],
        packageManager: null
      };

      // Check package.json for Node.js projects
      const pkgPath = path.join(dir, 'package.json');
      if (fs.existsSync(pkgPath)) {
        const pkg = JSON.parse(fs.readFileSync(pkgPath, 'utf-8'));
        stack.languages.push('JavaScript/TypeScript');
        stack.packageManager = detectPackageManager(dir);

        // Check for common frameworks
        const deps = { ...pkg.dependencies, ...pkg.devDependencies };
        if (deps['react']) stack.frameworks.push('React');
        if (deps['vue']) stack.frameworks.push('Vue');
        if (deps['@angular/core']) stack.frameworks.push('Angular');
        if (deps['next']) stack.frameworks.push('Next.js');
        if (deps['express']) stack.frameworks.push('Express');

        // Store libraries (top 10 by importance)
        stack.libraries = Object.keys(deps).slice(0, 10);
      }

      // Check for Python
      if (fs.existsSync(path.join(dir, 'requirements.txt')) ||
          fs.existsSync(path.join(dir, 'setup.py')) ||
          fs.existsSync(path.join(dir, 'pyproject.toml'))) {
        stack.languages.push('Python');
        stack.packageManager = 'pip/poetry';
      }

      // Check for Rust
      if (fs.existsSync(path.join(dir, 'Cargo.toml'))) {
        stack.languages.push('Rust');
        stack.packageManager = 'cargo';
      }

      // Check for Go
      if (fs.existsSync(path.join(dir, 'go.mod'))) {
        stack.languages.push('Go');
        stack.packageManager = 'go mod';
      }

      return stack;
    }

    function detectPackageManager(dir) {
      if (fs.existsSync(path.join(dir, 'pnpm-lock.yaml'))) return 'pnpm';
      if (fs.existsSync(path.join(dir, 'yarn.lock'))) return 'yarn';
      if (fs.existsSync(path.join(dir, 'package-lock.json'))) return 'npm';
      return 'npm (default)';
    }

    function analyzeArchitecture(dir) {
      const arch = {
        structure: [],
        patterns: []
      };

      // Check common directory patterns
      const dirs = fs.readdirSync(dir, { withFileTypes: true })
        .filter(e => e.isDirectory() && !e.name.startsWith('.') && e.name !== 'node_modules')
        .map(e => e.name);

      arch.structure = dirs;

      // Detect architecture patterns
      if (dirs.includes('components') && dirs.includes('pages')) {
        arch.patterns.push('Component-based (likely React/Next.js)');
      }
      if (dirs.includes('models') && dirs.includes('views') && dirs.includes('controllers')) {
        arch.patterns.push('MVC pattern');
      }
      if (dirs.includes('src') && dirs.includes('tests')) {
        arch.patterns.push('Standard src/tests split');
      }
      if (dirs.includes('lib') || dirs.includes('utils')) {
        arch.patterns.push('Utility/helper separation');
      }

      return arch;
    }

    function detectConventions(dir) {
      const conventions = {
        linting: [],
        formatting: [],
        typescript: false
      };

      if (fs.existsSync(path.join(dir, '.eslintrc.json')) ||
          fs.existsSync(path.join(dir, '.eslintrc.js'))) {
        conventions.linting.push('ESLint');
      }

      if (fs.existsSync(path.join(dir, '.prettierrc')) ||
          fs.existsSync(path.join(dir, '.prettierrc.json'))) {
        conventions.formatting.push('Prettier');
      }

      if (fs.existsSync(path.join(dir, 'tsconfig.json'))) {
        conventions.typescript = true;
      }

      return conventions;
    }

    function detectTesting(dir) {
      const testing = {
        frameworks: [],
        hasTests: false,
        testDirs: []
      };

      // Check for test directories
      const testDirs = ['tests', 'test', '__tests__', 'spec'];
      testing.testDirs = testDirs.filter(d => fs.existsSync(path.join(dir, d)));
      testing.hasTests = testing.testDirs.length > 0;

      // Check package.json for test frameworks
      const pkgPath = path.join(dir, 'package.json');
      if (fs.existsSync(pkgPath)) {
        const pkg = JSON.parse(fs.readFileSync(pkgPath, 'utf-8'));
        const deps = { ...pkg.dependencies, ...pkg.devDependencies };

        if (deps['jest']) testing.frameworks.push('Jest');
        if (deps['mocha']) testing.frameworks.push('Mocha');
        if (deps['vitest']) testing.frameworks.push('Vitest');
        if (deps['@playwright/test']) testing.frameworks.push('Playwright');
      }

      return testing;
    }

    /**
     * Render analysis results to CODEBASE.md using template
     */
    export async function renderCodebaseReport(analysis, outputPath) {
      // Prepare variables for template
      const vars = {
        analyzedAt: analysis.metadata.analyzedAt,
        languages: analysis.techStack.languages.join(', ') || 'Not detected',
        frameworks: analysis.techStack.frameworks.join(', ') || 'None detected',
        packageManager: analysis.techStack.packageManager || 'None',
        libraries: analysis.techStack.libraries.join(', ') || 'None',
        structure: analysis.architecture.structure.join(', ') || 'Flat structure',
        patterns: analysis.architecture.patterns.join(', ') || 'No clear pattern detected',
        linting: analysis.conventions.linting.join(', ') || 'None',
        formatting: analysis.conventions.formatting.join(', ') || 'None',
        typescript: analysis.conventions.typescript ? 'Yes' : 'No',
        testFrameworks: analysis.testing.frameworks.join(', ') || 'None',
        testDirs: analysis.testing.testDirs.join(', ') || 'None',
        hasTests: analysis.testing.hasTests ? 'Yes' : 'No'
      };

      // Use renderTemplate API correctly: renderTemplate(templateName, variables, templatesDir)
      const templatesDir = path.join(__dirname, '..', 'templates');
      const rendered = await renderTemplate('CODEBASE', vars, templatesDir);

      // Write rendered content to output path
      fs.writeFileSync(outputPath, rendered, 'utf-8');
    }

    // CLI execution
    if (import.meta.url === `file://${process.argv[1]}`) {
      const args = process.argv.slice(2);
      const outputArg = args.find(a => a.startsWith('--output='));
      const outputPath = outputArg ? outputArg.split('=')[1] : '.planning/CODEBASE.md';

      const analysis = await analyzeCodebase();
      await renderCodebaseReport(analysis, outputPath);

      console.log(`Codebase analysis complete. Report saved to: ${outputPath}`);
      process.exit(0);
    }
    ```

    WHY import named export: template-renderer.js exports `renderTemplate` as a named export, NOT a default export. Using `import { renderTemplate }` is correct.

    WHY write output manually: renderTemplate() returns the rendered string. We write it to the file using fs.writeFileSync(), giving us control over the output path.

    WHY separate detection functions: Tech stack, architecture, conventions, and testing are orthogonal concerns. Separate functions enable independent testing and future extensibility.

    WHY async: Future-proofing for potential async operations (file system promises, external tools).
  </action>
  <verify>
    ```bash
    # Verify script exists and uses ESM
    head -1 gsd/scripts/codebase-researcher.js | grep "#!/usr/bin/env node"
    grep "export.*function.*analyzeCodebase" gsd/scripts/codebase-researcher.js

    # Verify correct template-renderer API usage
    grep "import { renderTemplate }" gsd/scripts/codebase-researcher.js
    grep "renderTemplate('CODEBASE'" gsd/scripts/codebase-researcher.js

    # Test analysis (on GSD project itself)
    node gsd/scripts/codebase-researcher.js --output=.planning/CODEBASE-test.md
    ls .planning/CODEBASE-test.md
    ```
    Script should run and create CODEBASE-test.md with analysis of GSD project.
  </verify>
  <done>
    codebase-researcher.js exists, exports analyzeCodebase and renderCodebaseReport functions, detects tech stack/architecture/conventions/testing, uses correct renderTemplate() API, and renders results to CODEBASE.md template.
  </done>
</task>

<task type="auto">
  <name>Create CODEBASE.md template</name>
  <files>gsd/templates/CODEBASE.md</files>
  <action>
    Create gsd/templates/CODEBASE.md template for codebase research findings.

    **Template structure:**
    ```markdown
    ---
    type: "codebase-analysis"
    analyzed_at: "${analyzedAt}"
    schema: "gsd-codebase-v1"
    variables:
      - analyzedAt
      - languages
      - frameworks
      - packageManager
      - libraries
      - structure
      - patterns
      - linting
      - formatting
      - typescript
      - testFrameworks
      - testDirs
      - hasTests
    ---

    # Codebase Analysis

    This document contains automated analysis of the existing codebase, performed during GSD initialization.

    ## Tech Stack

    **Languages:** ${languages}

    **Frameworks:** ${frameworks}

    **Package Manager:** ${packageManager}

    **Key Libraries:**
    ${libraries}

    ## Architecture

    **Directory Structure:**
    ${structure}

    **Detected Patterns:**
    ${patterns}

    ## Code Conventions

    **Linting:** ${linting}

    **Formatting:** ${formatting}

    **TypeScript:** ${typescript}

    ## Testing Infrastructure

    **Test Frameworks:** ${testFrameworks}

    **Test Directories:** ${testDirs}

    **Has Tests:** ${hasTests}

    ## Recommendations

    When generating requirements and plans for this project:

    1. **Respect existing tech choices** - Don't suggest replacing ${frameworks} unless explicitly requested
    2. **Follow existing patterns** - ${patterns} indicates current architecture approach
    3. **Match conventions** - Use ${linting} and ${formatting} configurations
    4. **Build on testing setup** - ${testFrameworks} already in place
    5. **Consider constraints** - Existing structure (${structure}) limits certain architectural changes

    ## Notes

    This analysis is automated and may not capture all nuances. Review findings and adjust PROJECT.md/REQUIREMENTS.md as needed.

    **Generated by:** GSD codebase-researcher.js
    **Date:** ${analyzedAt}
    ```

    WHY use ${} not {{}}: template-renderer.js uses JavaScript template literals via Function constructor. It expects `${varName}` syntax, NOT `{{varName}}` Mustache syntax.

    WHY variables array in frontmatter: template-renderer.js reads this to validate all required variables are provided before rendering.

    WHY Recommendations section: Most important part. Raw analysis is data. Recommendations are actionable guidance for Claude generating requirements.

    WHY Notes section: Sets expectations. Automated analysis can't understand business logic, only structure. User should review.

    WHY frontmatter: Consistent with other GSD templates. Enables future validation/versioning.
  </action>
  <verify>
    ```bash
    # Verify template exists
    ls gsd/templates/CODEBASE.md

    # Verify frontmatter
    head -10 gsd/templates/CODEBASE.md | grep "type: \"codebase-analysis\""

    # Verify variable placeholders use ${} syntax (not {{}})
    grep "\${analyzedAt}" gsd/templates/CODEBASE.md
    grep "\${languages}" gsd/templates/CODEBASE.md
    grep "\${frameworks}" gsd/templates/CODEBASE.md

    # Should NOT contain {{}} syntax
    ! grep "{{" gsd/templates/CODEBASE.md
    ```
    Template should exist with frontmatter, variables array, and ${} placeholders (not {{}}).
  </verify>
  <done>
    CODEBASE.md template exists with frontmatter, variables array, analysis sections (tech stack, architecture, conventions, testing), recommendations, and ${} variable placeholders compatible with template-renderer.js.
  </done>
</task>

<task type="auto">
  <name>Run integration tests to verify new scripts</name>
  <files>none (verification task)</files>
  <action>
    Run the integration test suite to ensure new scripts integrate correctly with existing GSD infrastructure:

    ```bash
    node gsd/scripts/integration-test.js
    ```

    This verifies:
    - New scripts don't break existing workflows
    - Template rendering with CODEBASE.md template works
    - ESM imports/exports work correctly across script boundaries
    - No regressions in core GSD functionality

    WHY run integration tests: New scripts interact with existing infrastructure (template-renderer.js, file-ops.js). Integration tests catch issues like:
    - Import path errors
    - API mismatches (like incorrect template-renderer usage)
    - File system permission issues
    - Template syntax errors that break rendering

    WHY as final task: All artifacts must exist before testing integration. This task validates the entire phase's work together.
  </action>
  <verify>
    ```bash
    node gsd/scripts/integration-test.js
    echo "Exit code: $?"
    ```
    Integration tests should pass with exit code 0. All test cases should complete successfully.
  </verify>
  <done>
    Integration tests pass, confirming new codebase detection/research scripts integrate correctly with existing GSD infrastructure.
  </done>
</task>

</tasks>

<verification>
Verify all scripts and templates work together:

```bash
# Test codebase detection
node gsd/scripts/codebase-detector.js
# Should output: { isExisting: true, indicators: [...], confidence: "HIGH" }

# Test codebase research
node gsd/scripts/codebase-researcher.js --output=.planning/CODEBASE-test.md

# Verify CODEBASE-test.md was created
cat .planning/CODEBASE-test.md

# Check for expected sections
grep "Tech Stack" .planning/CODEBASE-test.md
grep "Architecture" .planning/CODEBASE-test.md
grep "Recommendations" .planning/CODEBASE-test.md

# Verify integration with existing scripts (template-renderer.js)
grep "import.*renderTemplate" gsd/scripts/codebase-researcher.js

# Run integration tests
node gsd/scripts/integration-test.js

# Clean up test file
rm .planning/CODEBASE-test.md 2>/dev/null || true
```

All scripts should:
- Run without errors
- Use ESM module syntax
- Export documented functions
- Work with existing infrastructure (template-renderer.js)
- Produce valid markdown output
</verification>

<success_criteria>
1. codebase-detector.js exists and detects dependency files, source directories, config files
2. Detection script exports detectExistingCodebase function and runs as CLI
3. Detection outputs JSON with isExisting, indicators, confidence fields
4. codebase-researcher.js exists and analyzes tech stack, architecture, conventions, testing
5. Research script exports analyzeCodebase and renderCodebaseReport functions
6. Research script uses correct template-renderer.js API: renderTemplate(name, vars, dir)
7. CODEBASE.md template exists with frontmatter, variables array, and ${} syntax
8. All scripts use ESM syntax (import/export)
9. Scripts are executable (#!/usr/bin/env node shebang)
10. Integration tests pass (detection → research → CODEBASE.md generation)
</success_criteria>

<output>
After completion, create `.planning/phases/09-ensure-starting-a-new-project-is-better-worded-even-when-work-withing-an-existing-application-that-is-simply-intializing-gsd-for-the-first/09-04-SUMMARY.md`
</output>
